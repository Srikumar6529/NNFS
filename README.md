# NNFS
Neural Network from Scratch
The project uses a neural network with single hidden layers to classify images from the MNIST dataset. The network architecture includes ReLU activation functions and a softmax output layer for multiclass classification.

## Project Overview

- **Dataset**: MNIST (Handwritten Digit Recognition)
- **Neural Network Architecture**: Input Layer (784 neurons) - Hidden Layers (16 neurons) - Output Layer (10 neurons)
- **Activation Functions**: ReLU for hidden layers, Softmax for the output layer
- **Optimization Algorithm**: Stochastic Gradient Descent (SGD)
- **Training Epochs**: 100
- **Batch Size**: 64
- **Learning Rate**: 0.01

Results
After training the neural network for 100 epochs, the project achieved a test accuracy of approximately 98.13%.
